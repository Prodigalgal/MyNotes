# 1、选型

## 1、日志监控

### 1、主要功能

主要功能：采集、过滤、转发、储存、可视化

采集、过滤、转发组件：Logstash、Filebeat、Fluentbit、Fluentd、Promtail

储存：Elasticsearch、Kafak、Loki

可视化：Kibana、Grafana



### 2、最终选型

日志监控平台选择使用 Elasticsearch、Filebeat、Kibana，原因如下：

- 优点：
  - Filebeat 相比于 Logstash 较为轻量，对于节点负担较小

  - 通过 ECK 搭建 Elasticsearch、Filebeat、Kibana 在维护与升级方面简单方便，组件之间有较好的兼容性

  - ECK 内置大量的监控规则，安装 Promethus 后，开箱即用

  - 对于高可用，由于 ECK 组件之间互相解耦，并且 ECK 部署的同类组件自带 Pod 反亲和性，会自然的部署在不同的节点上，只要设置多个组件副本，在单节点上出现各种组件故障不会影响到整体，减小故障域
  
- 缺点：

  - 自定义参数较为困难
  - 官方文档不够详细

不选用 Fluentbit、Fluentd 原因如下：

- 搭建过程繁琐易出错，需要大量的配置
- 由于转发过程依赖多种插件，与下游日志接受组件兼容性不好
- 官方文档异常简陋，学习曲线过高
- 由于增加许多的配置，后期维护难度大幅增加
- 虽然使用 Fluentd 作为转发组件，但由于其性能原因，并不适合



## 2、告警监控

### 1、主要功能

告警监控主要分为：采集、处理

目前主要平台有：Zabbix、Prometheus、OpenFalcon、TICK、Bosun

数据采集：负责指标的采集、过滤、汇总、储存

数据处理：负责数据分析、数据可视化、告警触发、告警



### 2、最终选型

告警监控平台选用 Prometheus 等一系列组件，原因如下：

- 优点：
  - 使用 kube-prometheus-stack 可以快速搭建一整套完整的告警监控平台，使用 values 文件可以任意自定义平台，包括各个组件的开关、伸缩、规则等
  - 自带时序数据库具备较高的性能，且节省空间
  - 多样化储存后端，配置简单
  - 与 Grafana 兼容较好，使用 PromQL 等方便展示数据
  - 单个组件结构简单，通过 values 文件扩展方便
  - 使用 pull 模式拉取数据降低系统耦合性，增强系统整体的稳定性
  - 配置简单，稍微配置就可以收集丰富的指标，甚至可以做到开箱即用
  - 与其他存储数据库兼容性高
  - 告警通知与告警触发解耦，系统整体较为稳定
  - 官方文档较为明晰
  - 社区活跃
  - 故障域较小
  - 关于高可用，也同日志监控方面，由于 Prometheus 各个组件相互解耦，并且组件较小，只要设定了 Pod 之间的反亲和性，可以将故障域缩小
- 缺点：
  - 引入的 values 文件非常大，包含了所有组件的各种规则，学习曲线较陡
  - 官方文档示例不足

不选用其余告警平台的原因如下：

- 成熟度不高
- 设计架构过于复杂，维护难度高
- 社区不够活跃
- 性能不够
- 规则自定义较为复杂
- 指标采集不够丰富
- 使用关系型数据库，不适合
- 故障域较大



# 2、搭建流程

## 1、安装 Helm

~~~bash
curl https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3 | bash
~~~



## 2、安装 elastic-operator

使用 elastic-operator 搭建 Elasticsearch、Kibana、Filebeat

1. 安装自定义资源

   - ~~~bash
     kubectl create -f https://download.elastic.co/downloads/eck/2.6.1/crds.yaml
     ~~~

2. 安装 ECK Operator

   - ~~~bash
     kubectl apply -f https://download.elastic.co/downloads/eck/2.6.1/operator.yaml
     ~~~

3. 查看 Operator 日志，验证安装成功

   - ~~~bash
     kubectl -n elastic-system logs -f statefulset.apps/elastic-operator
     ~~~

4. 定义 Elasticsearch、Kibana 的 yml 文件

   - ~~~yaml
     apiVersion: v1
     kind: Namespace
     metadata:
       name: eck-stack
     ---
     apiVersion: elasticsearch.k8s.elastic.co/v1
     kind: Elasticsearch
     metadata:
       name: eckes
       namespace: eck-stack
     spec:
       version: 8.6.2
       nodeSets:
         - name: default
           count: 3
           config:
             node.roles: [ "master", "data", "ingest" ]
             xpack.ml.enabled: true
             node.store.allow_mmap: false
           podTemplate:
             spec:
               initContainers:
                 - name: vm-max-map
                   securityContext:
                     privileged: true
                   command: [ 'sh', '-c', 'sysctl -w vm.max_map_count=262144' ]
           volumeClaimTemplates:
             - metadata:
                 name: elasticsearch-data
               spec:
                 accessModes:
                   - ReadWriteMany
                 resources:
                   requests:
                     storage: 1Gi
                 storageClassName: nfs-storage
       http:
         service:
           spec:
             ports:
               - port: 9200
                 targetPort: 9200
                 nodePort: 31920
                 name: https
               - port: 9300
                 targetPort: 9300
                 nodePort: 31930
                 name: inner
             type: NodePort
     ---
     apiVersion: kibana.k8s.elastic.co/v1
     kind: Kibana
     metadata:
       name: eckkb
       namespace: eck-stack
     spec:
       version: 8.6.2
       count: 2
       elasticsearchRef:
         name: eckes
       config:
         monitoring.ui.container.elasticsearch.enabled: true
       http:
         service:
           spec:
             ports:
               - port: 5601
                 targetPort: 5601
                 nodePort: 31561
                 name: https
             type: NodePort
     ~~~

5. 获取 ES 默认密码

   - ~~~bash
     PASSWORD=$(kubectl get secret eckes-es-elastic-user -o go-template='{{.data.elastic | base64decode}}' -n eck-stack)
     ~~~

   - ~~~bash
     echo ${PASSWORD}
     ~~~

6. 测试访问

   - ~~~bash
     root@m01:~# curl -u "elastic:$PASSWORD" -k "https://localhost:31920"
     {
       "name" : "eckes-es-default-0",
       "cluster_name" : "eckes",
       "cluster_uuid" : "7VkE9YNuQje4A6MUiixKKQ",
       "version" : {
         "number" : "7.10.0",
         "build_flavor" : "default",
         "build_type" : "docker",
         "build_hash" : "51e9d6f22758d0374a0f3f5c6e8f3a7997850f96",
         "build_date" : "2020-11-09T21:30:33.964949Z",
         "build_snapshot" : false,
         "lucene_version" : "8.7.0",
         "minimum_wire_compatibility_version" : "6.8.0",
         "minimum_index_compatibility_version" : "6.0.0-beta1"
       },
       "tagline" : "You Know, for Search"
     }
     ~~~

7. 定义 Filebeat 的 yml 文件

   - ~~~yaml
     apiVersion: beat.k8s.elastic.co/v1beta1
     kind: Beat
     metadata:
       name: eckfb
       namespace: eck-stack
     spec:
       type: filebeat
       version: 8.6.2
       elasticsearchRef:
         name: eckes
       kibanaRef:
         name: eckkb
       config:
         filebeat.inputs:
           - type: container
             id: log-gen-json
             paths:
               - /var/log/containers/log-gen-json*.log
             fields:
               source: log-gen-json
         processors:
           - add_host_metadata: {}
           - add_kubernetes_metadata: {}
     #      - drop_fields:
     #          fields: [ "agent", "ecs", "container", "host", "input", "log", "offset", "stream", "kubernetes.node", "kubernetes.pod", "kubernetes.replicaset", "kubernetes.namespace_uid", "kubernetes.labels.pod-template-hash" ]
     #          ignore_missing: true
     #      - decode_json_fields:
     #          fields: [ "message" ]
     #          target: ""
     #          overwrite_keys: false
     #          process_array: false
     #          max_depth: 1
         setup:
           template:
           	enabled: false
         	overwrite: true
           ilm:
           	enabled: false
         
         output.elasticsearch:
           hosts: [ "http://eckes-es-http:9200" ]
           username: "elastic"
           # 填入上一步获取的密码
           password: ${PASSWORD}
           index: "product-other-log-%{+yyyy.MM.dd}"
           indices:
             - index: "log-gen-json-%{+yyyy.MM.dd}"
               when.contains:
                 kubernetes.labels.app: "log-gen-json"
     #      pipelines:
     #        - pipeline: "log-gen-json-pipeline"
     #          when.or:
     #            - contains:
     #                kubernetes.labels.app: "log-gen-json"
       daemonSet:
         podTemplate:
           spec:
             serviceAccountName: filebeat
             automountServiceAccountToken: true
             terminationGracePeriodSeconds: 30
             dnsPolicy: ClusterFirstWithHostNet
             hostNetwork: true
             containers:
               - name: filebeat
                 securityContext:
                   runAsUser: 0
                   privileged: true
                 volumeMounts:
                   - name: varlogcontainers
                     mountPath: /var/log/containers
                   - name: varlogpods
                     mountPath: /var/log/pods
                   - name: varlibdockercontainers
                     mountPath: /var/lib/docker/containers
                 env:
                   - name: NODE_NAME
                     valueFrom:
                       fieldRef:
                         fieldPath: spec.nodeName
             volumes:
               - name: varlogcontainers
                 hostPath:
                   path: /var/log/containers
               - name: varlogpods
                 hostPath:
                   path: /var/log/pods
               - name: varlibdockercontainers
                 hostPath:
                   path: /var/lib/docker/containers
     ---
     apiVersion: rbac.authorization.k8s.io/v1
     kind: ClusterRole
     metadata:
       name: filebeat
     rules:
       - apiGroups: [ "" ]
         resources:
           - namespaces
           - pods
           - nodes
         verbs:
           - get
           - watch
           - list
     ---
     apiVersion: v1
     kind: ServiceAccount
     metadata:
       name: filebeat
       namespace: eck-stack
     ---
     apiVersion: rbac.authorization.k8s.io/v1
     kind: ClusterRoleBinding
     metadata:
       name: filebeat
     subjects:
       - kind: ServiceAccount
         name: filebeat
         namespace: eck-stack
     roleRef:
       kind: ClusterRole
       name: filebeat
       apiGroup: rbac.authorization.k8s.io
     ~~~

**注意**：

- 以上自定义资源默认安装在 **elastic-system** 命名空间 
- 删除 CRD 将连带删除集群所有命名空间中的所有自定义资源，无论这些资源是由单个 Operator 还是多个 Operator 管理



## 3、安装 kube-prometheus-stack

使用 kube-prometheus-stack 搭建 Prometheus、Grafana、kube-state-metrics

1. 将 prometheus-community 仓库添加到 Helm repo，并更新仓库

   - ~~~bash
     helm repo add prometheus-community https://prometheus-community.github.io/helm-charts
     ~~~

   - ~~~bash
     helm repo update
     ~~~

2. 获取 values 文件导出为 kube-operator-stack-config.yml，进行自定义配置

   - 修改 Grafana、Prometheus、AlterManager 对应的 Service type 为 Nodeport，提供对外访问能力

   - 并修改副本数量，避免单机故障

   - 修改 AlterManager 的告警发送通道，使用 Email 发送

   - ~~~bash
     helm show values prometheus-community/kube-prometheus-stack > kube-operator-stack-config.yml
     ~~~

3. 安装 kube-prometheus-stack

   - ~~~bash
     helm install kube-prometheus-stack prometheus-community/kube-prometheus-stack --create-namespace --namespace prometheus -f kube-operator-stack-config.yml --version 45.7.1
     ~~~

4. 获取 Grafana 默认账号密码登录

   - ~~~bash
     kubectl get secret kube-prometheus-stack-grafana -n prometheus -o go-template='{{index .data "admin-password"}}' | base64 -d
     ~~~

   - ~~~bash
     kubectl get secret kube-prometheus-stack-grafana -n prometheus -o go-template='{{index .data "admin-user"}}' | base64 -d
     ~~~

5. 后续有修改 kube-operator-stack-config.yml 文件需要更新

   - ~~~bash
     helm upgrade -n prometheus kube-prometheus-stack -f kube-operator-stack-config.yml --version 45.7.1 prometheus-community/kube-prometheus-stack
     ~~~





